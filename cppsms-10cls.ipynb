{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Import Libraries","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom skimage import transform\nimport numpy as np\nimport cv2\nimport os\nimport glob\nimport pandas as pd\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport imageio","metadata":{"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"collapsed":false,"execution":{"iopub.status.busy":"2023-01-21T13:01:58.910981Z","iopub.execute_input":"2023-01-21T13:01:58.911437Z","iopub.status.idle":"2023-01-21T13:02:00.261591Z","shell.execute_reply.started":"2023-01-21T13:01:58.911361Z","shell.execute_reply":"2023-01-21T13:02:00.260639Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"##  Feature Extraction","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","source":"def image_to_feature_vector(image, size=(80, 80)):\n    image = transform.resize(image, size)\n    return image.flatten()","metadata":{"execution":{"iopub.status.busy":"2023-01-21T13:02:00.263596Z","iopub.execute_input":"2023-01-21T13:02:00.263940Z","iopub.status.idle":"2023-01-21T13:02:00.271986Z","shell.execute_reply.started":"2023-01-21T13:02:00.263906Z","shell.execute_reply":"2023-01-21T13:02:00.270361Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def extract_color_histogram(image, bins=(4, 4, 4)):\n    image = cv2.resize(image, (80, 80))\n    # extract a 3D color histogram from the HSV color space using\n    # the supplied number of `bins` per channel\n    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n    hist = cv2.calcHist([hsv], [0, 1, 2], None, bins,\n                        [0, 180, 0, 256, 0, 256])\n    cv2.normalize(hist, hist)\n    # return the flattened histogram as the feature vector\n    return hist.flatten()","metadata":{"execution":{"iopub.status.busy":"2023-01-21T13:02:00.273496Z","iopub.execute_input":"2023-01-21T13:02:00.274579Z","iopub.status.idle":"2023-01-21T13:02:00.284768Z","shell.execute_reply.started":"2023-01-21T13:02:00.274543Z","shell.execute_reply":"2023-01-21T13:02:00.283855Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from skimage.feature import hog\ndef HOG(image):\n    img = transform.resize(image, (80, 80))\n    fd = hog(image, \n             orientations=8, \n             pixels_per_cell=(8,8),\n             cells_per_block=(3,3), \n             block_norm='L2-Hys', \n             visualize=False, \n             transform_sqrt=False,\n             channel_axis=-1)\n    return fd","metadata":{"execution":{"iopub.status.busy":"2023-01-21T13:02:00.287119Z","iopub.execute_input":"2023-01-21T13:02:00.287552Z","iopub.status.idle":"2023-01-21T13:02:00.425310Z","shell.execute_reply.started":"2023-01-21T13:02:00.287518Z","shell.execute_reply":"2023-01-21T13:02:00.424459Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from scipy.fftpack import dct, idct\nfrom skimage.color import rgb2gray\ndef DCT_2D(image, num_coeffs=100, width=80): \n    # implement 2D DCT\n    def dct2(a):\n        return dct(dct(a.T, norm='ortho').T, norm='ortho')\n    image = rgb2gray(image) \n    image = transform.resize(image, (width, width))\n    imageF = dct2(image)\n    zigzag = np.concatenate([np.diagonal(imageF[::-1,:], i)[::(2*(i % 2)-1)] for i in range(1-imageF.shape[0], imageF.shape[0])])\n    return zigzag[:num_coeffs]","metadata":{"execution":{"iopub.status.busy":"2023-01-21T13:02:00.426692Z","iopub.execute_input":"2023-01-21T13:02:00.427036Z","iopub.status.idle":"2023-01-21T13:02:00.442386Z","shell.execute_reply.started":"2023-01-21T13:02:00.427001Z","shell.execute_reply":"2023-01-21T13:02:00.441547Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from skimage.feature import graycomatrix, graycoprops\ndef co_occurence(image):\n    image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n    features = []\n    for j in [1, 3, 5, 7]:\n        for k in [0, np.pi/4, np.pi/2, 3*np.pi/4, np.pi]:\n            GLCM_properties = []\n            GLCM = graycomatrix(image, [j], [k])\n            GLCM_Energy = graycoprops(GLCM, 'energy')\n            GLCM_properties.append(np.squeeze(GLCM_Energy))\n            GLCM_corr = graycoprops(GLCM, 'correlation')\n            GLCM_properties.append(np.squeeze(GLCM_corr))\n            GLCM_diss = graycoprops(GLCM, 'dissimilarity')\n            GLCM_properties.append(np.squeeze(GLCM_diss))\n            GLCM_hom = graycoprops(GLCM, 'homogeneity')\n            GLCM_properties.append(np.squeeze(GLCM_hom))       \n            GLCM_contr = graycoprops(GLCM, 'contrast')\n            GLCM_properties.append(np.squeeze(GLCM_contr))\n            features += GLCM_properties\n    return list(features)","metadata":{"execution":{"iopub.status.busy":"2023-01-21T13:02:00.443642Z","iopub.execute_input":"2023-01-21T13:02:00.444143Z","iopub.status.idle":"2023-01-21T13:02:00.452352Z","shell.execute_reply.started":"2023-01-21T13:02:00.444106Z","shell.execute_reply":"2023-01-21T13:02:00.451378Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"images = []\nlabels = []","metadata":{"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"collapsed":false,"execution":{"iopub.status.busy":"2023-01-21T13:02:00.453861Z","iopub.execute_input":"2023-01-21T13:02:00.454451Z","iopub.status.idle":"2023-01-21T13:02:00.464150Z","shell.execute_reply.started":"2023-01-21T13:02:00.454417Z","shell.execute_reply":"2023-01-21T13:02:00.463260Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"pathName = \"/kaggle/input/coreldb-10cls/CorelDB\"\ni = 0\nfor dirName, subdirList, fileList in os.walk(pathName):\n    for fileName in fileList:\n        base, extension = os.path.splitext(fileName)\n        if extension == '.jpg' or extension == '.JPG' or extension == '.png' or extension == '.PNG':\n\n            imagePath = f\"{dirName}/{fileName}\"\n            image = imageio.imread(imagePath)\n            images.append(image)\n            \n            label = os.path.basename(dirName)\n            labels.append(label)\n\n            if i > 0 and i % 1000 == 0:\n                print(f\"{i}/10800\")\n\n            i += 1","metadata":{"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"collapsed":false,"execution":{"iopub.status.busy":"2023-01-21T13:02:00.465616Z","iopub.execute_input":"2023-01-21T13:02:00.465960Z","iopub.status.idle":"2023-01-21T13:02:37.009487Z","shell.execute_reply.started":"2023-01-21T13:02:00.465927Z","shell.execute_reply":"2023-01-21T13:02:37.008509Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"1000/10800\n2000/10800\n3000/10800\n4000/10800\n5000/10800\n6000/10800\n7000/10800\n8000/10800\n9000/10800\n10000/10800\n","output_type":"stream"}]},{"cell_type":"code","source":"feature_extraction_method = extract_color_histogram\nX = np.array(list(map(feature_extraction_method, images)))\nprint(X.shape)\n\nle = LabelEncoder()\ny = le.fit_transform(labels)\nprint(y.shape)","metadata":{"execution":{"iopub.status.busy":"2023-01-21T13:02:37.011074Z","iopub.execute_input":"2023-01-21T13:02:37.011452Z","iopub.status.idle":"2023-01-21T13:02:38.129358Z","shell.execute_reply.started":"2023-01-21T13:02:37.011416Z","shell.execute_reply":"2023-01-21T13:02:38.128342Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"(10800, 64)\n(10800,)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Data Preprocessing","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n\nprint(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","metadata":{"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"collapsed":false,"execution":{"iopub.status.busy":"2023-01-21T13:02:38.132812Z","iopub.execute_input":"2023-01-21T13:02:38.133419Z","iopub.status.idle":"2023-01-21T13:02:38.143966Z","shell.execute_reply.started":"2023-01-21T13:02:38.133380Z","shell.execute_reply":"2023-01-21T13:02:38.142928Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"(8640, 64)\n(2160, 64)\n(8640,)\n(2160,)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## PCA","metadata":{}},{"cell_type":"code","source":"from sklearn.decomposition import PCA\npca = PCA(n_components=10)\nX_pca_train = pca.fit_transform(X_train)\nX_pca_test = pca.transform(X_test)\ny_pca_train = y_train\ny_pca_test = y_test\n\nprint(X_pca_train.shape)\nprint(X_pca_test.shape)\n\nexplained_variance = pca.explained_variance_\nplt.plot(np.cumsum((pca.explained_variance_)))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-01-21T13:03:08.193159Z","iopub.execute_input":"2023-01-21T13:03:08.193848Z","iopub.status.idle":"2023-01-21T13:03:08.510992Z","shell.execute_reply.started":"2023-01-21T13:03:08.193813Z","shell.execute_reply":"2023-01-21T13:03:08.510076Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"(8640, 10)\n(2160, 10)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":"##  Classification","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","source":"from sklearn import svm\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\nmodel_params = {\n    'svm': {\n        'model': svm.SVC(gamma='auto'),\n        'params' : {\n            'C': [1, 10, 20, 30],\n            'kernel': ['sigmoid', 'rbf', 'linear', 'poly']\n        }  \n    },\n    'random_forest': {\n        'model': RandomForestClassifier(),\n        'params' : {\n            'n_estimators': [1, 5, 10, 50, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]\n        }\n    },\n    'logistic_regression' : {\n        'model': LogisticRegression(solver='liblinear',multi_class='auto'),\n        'params': {\n            'C': [1, 5, 10, 50, 100]\n        }\n    },\n    'KNN' : {\n        'model': KNeighborsClassifier(),\n        'params': {\n            'n_neighbors': [1 ,3, 5, 7, 9, 11, 13],\n            'metric': [\"minkowski\", \"euclidean\", \"manhattan\", \"chebyshev\", \"cosine\", \"hamming\", \"canberra\", \"braycurtis\"]\n        }\n    }\n    \n}","metadata":{"execution":{"iopub.status.busy":"2023-01-21T13:03:14.012293Z","iopub.execute_input":"2023-01-21T13:03:14.012667Z","iopub.status.idle":"2023-01-21T13:03:14.116758Z","shell.execute_reply.started":"2023-01-21T13:03:14.012636Z","shell.execute_reply":"2023-01-21T13:03:14.115776Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nscores = []\n\nfor model_name, mp in model_params.items():\n    clf = GridSearchCV(mp['model'], mp['params'], cv=3, return_train_score=True, verbose=3)\n    clf.fit(X_pca_train, y_pca_train)\n    scores.append({\n        'model': model_name,\n        'best_score': clf.best_score_,\n        'best_params': clf.best_params_\n    })","metadata":{"execution":{"iopub.status.busy":"2023-01-21T13:03:14.273083Z","iopub.execute_input":"2023-01-21T13:03:14.274104Z","iopub.status.idle":"2023-01-21T13:14:51.946390Z","shell.execute_reply.started":"2023-01-21T13:03:14.274064Z","shell.execute_reply":"2023-01-21T13:14:51.945270Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Fitting 3 folds for each of 16 candidates, totalling 48 fits\n[CV 1/3] END C=1, kernel=sigmoid;, score=(train=0.348, test=0.344) total time=   4.0s\n[CV 2/3] END C=1, kernel=sigmoid;, score=(train=0.344, test=0.342) total time=   4.5s\n[CV 3/3] END C=1, kernel=sigmoid;, score=(train=0.345, test=0.334) total time=   4.0s\n[CV 1/3] END C=1, kernel=rbf;, score=(train=0.373, test=0.360) total time=   3.5s\n[CV 2/3] END C=1, kernel=rbf;, score=(train=0.356, test=0.365) total time=   3.6s\n[CV 3/3] END C=1, kernel=rbf;, score=(train=0.366, test=0.351) total time=   3.4s\n[CV 1/3] END C=1, kernel=linear;, score=(train=0.372, test=0.361) total time=   2.1s\n[CV 2/3] END C=1, kernel=linear;, score=(train=0.357, test=0.372) total time=   2.1s\n[CV 3/3] END C=1, kernel=linear;, score=(train=0.366, test=0.350) total time=   2.0s\n[CV 1/3] END C=1, kernel=poly;, score=(train=0.245, test=0.245) total time=   2.4s\n[CV 2/3] END C=1, kernel=poly;, score=(train=0.245, test=0.245) total time=   2.4s\n[CV 3/3] END C=1, kernel=poly;, score=(train=0.245, test=0.245) total time=   2.5s\n[CV 1/3] END C=10, kernel=sigmoid;, score=(train=0.371, test=0.361) total time=   4.3s\n[CV 2/3] END C=10, kernel=sigmoid;, score=(train=0.356, test=0.371) total time=   4.1s\n[CV 3/3] END C=10, kernel=sigmoid;, score=(train=0.365, test=0.349) total time=   4.0s\n[CV 1/3] END C=10, kernel=rbf;, score=(train=0.416, test=0.397) total time=   3.0s\n[CV 2/3] END C=10, kernel=rbf;, score=(train=0.401, test=0.412) total time=   3.1s\n[CV 3/3] END C=10, kernel=rbf;, score=(train=0.412, test=0.398) total time=   3.3s\n[CV 1/3] END C=10, kernel=linear;, score=(train=0.374, test=0.362) total time=   2.5s\n[CV 2/3] END C=10, kernel=linear;, score=(train=0.362, test=0.373) total time=   2.7s\n[CV 3/3] END C=10, kernel=linear;, score=(train=0.371, test=0.354) total time=   2.4s\n[CV 1/3] END C=10, kernel=poly;, score=(train=0.245, test=0.245) total time=   2.5s\n[CV 2/3] END C=10, kernel=poly;, score=(train=0.245, test=0.245) total time=   2.8s\n[CV 3/3] END C=10, kernel=poly;, score=(train=0.245, test=0.245) total time=   2.5s\n[CV 1/3] END C=20, kernel=sigmoid;, score=(train=0.371, test=0.361) total time=   4.0s\n[CV 2/3] END C=20, kernel=sigmoid;, score=(train=0.359, test=0.370) total time=   4.5s\n[CV 3/3] END C=20, kernel=sigmoid;, score=(train=0.366, test=0.351) total time=   4.2s\n[CV 1/3] END C=20, kernel=rbf;, score=(train=0.439, test=0.409) total time=   3.1s\n[CV 2/3] END C=20, kernel=rbf;, score=(train=0.416, test=0.432) total time=   3.2s\n[CV 3/3] END C=20, kernel=rbf;, score=(train=0.429, test=0.412) total time=   3.0s\n[CV 1/3] END C=20, kernel=linear;, score=(train=0.374, test=0.362) total time=   2.7s\n[CV 2/3] END C=20, kernel=linear;, score=(train=0.363, test=0.373) total time=   3.5s\n[CV 3/3] END C=20, kernel=linear;, score=(train=0.372, test=0.355) total time=   2.7s\n[CV 1/3] END C=20, kernel=poly;, score=(train=0.245, test=0.245) total time=   2.8s\n[CV 2/3] END C=20, kernel=poly;, score=(train=0.245, test=0.245) total time=   2.6s\n[CV 3/3] END C=20, kernel=poly;, score=(train=0.245, test=0.245) total time=   2.6s\n[CV 1/3] END C=30, kernel=sigmoid;, score=(train=0.372, test=0.360) total time=   4.4s\n[CV 2/3] END C=30, kernel=sigmoid;, score=(train=0.359, test=0.373) total time=   4.0s\n[CV 3/3] END C=30, kernel=sigmoid;, score=(train=0.366, test=0.351) total time=   4.8s\n[CV 1/3] END C=30, kernel=rbf;, score=(train=0.445, test=0.415) total time=   3.2s\n[CV 2/3] END C=30, kernel=rbf;, score=(train=0.429, test=0.437) total time=   3.2s\n[CV 3/3] END C=30, kernel=rbf;, score=(train=0.436, test=0.415) total time=   3.1s\n[CV 1/3] END C=30, kernel=linear;, score=(train=0.375, test=0.362) total time=   3.1s\n[CV 2/3] END C=30, kernel=linear;, score=(train=0.363, test=0.373) total time=   2.9s\n[CV 3/3] END C=30, kernel=linear;, score=(train=0.372, test=0.355) total time=   3.8s\n[CV 1/3] END C=30, kernel=poly;, score=(train=0.245, test=0.245) total time=   2.6s\n[CV 2/3] END C=30, kernel=poly;, score=(train=0.245, test=0.245) total time=   2.6s\n[CV 3/3] END C=30, kernel=poly;, score=(train=0.245, test=0.245) total time=   2.9s\nFitting 3 folds for each of 14 candidates, totalling 42 fits\n[CV 1/3] END n_estimators=1;, score=(train=0.744, test=0.309) total time=   0.0s\n[CV 2/3] END n_estimators=1;, score=(train=0.740, test=0.298) total time=   0.0s\n[CV 3/3] END n_estimators=1;, score=(train=0.741, test=0.299) total time=   0.0s\n[CV 1/3] END n_estimators=5;, score=(train=0.937, test=0.389) total time=   0.1s\n[CV 2/3] END n_estimators=5;, score=(train=0.939, test=0.385) total time=   0.1s\n[CV 3/3] END n_estimators=5;, score=(train=0.940, test=0.382) total time=   0.1s\n[CV 1/3] END n_estimators=10;, score=(train=0.987, test=0.424) total time=   0.2s\n[CV 2/3] END n_estimators=10;, score=(train=0.985, test=0.413) total time=   0.2s\n[CV 3/3] END n_estimators=10;, score=(train=0.985, test=0.426) total time=   0.2s\n[CV 1/3] END n_estimators=50;, score=(train=1.000, test=0.454) total time=   0.9s\n[CV 2/3] END n_estimators=50;, score=(train=1.000, test=0.464) total time=   0.9s\n[CV 3/3] END n_estimators=50;, score=(train=1.000, test=0.459) total time=   1.1s\n[CV 1/3] END n_estimators=100;, score=(train=1.000, test=0.461) total time=   1.8s\n[CV 2/3] END n_estimators=100;, score=(train=1.000, test=0.472) total time=   1.7s\n[CV 3/3] END n_estimators=100;, score=(train=1.000, test=0.474) total time=   1.8s\n[CV 1/3] END n_estimators=200;, score=(train=1.000, test=0.458) total time=   3.9s\n[CV 2/3] END n_estimators=200;, score=(train=1.000, test=0.473) total time=   3.8s\n[CV 3/3] END n_estimators=200;, score=(train=1.000, test=0.472) total time=   3.5s\n[CV 1/3] END n_estimators=300;, score=(train=1.000, test=0.466) total time=   5.5s\n[CV 2/3] END n_estimators=300;, score=(train=1.000, test=0.473) total time=   5.4s\n[CV 3/3] END n_estimators=300;, score=(train=1.000, test=0.477) total time=   5.5s\n[CV 1/3] END n_estimators=400;, score=(train=1.000, test=0.472) total time=   7.8s\n[CV 2/3] END n_estimators=400;, score=(train=1.000, test=0.481) total time=   7.1s\n[CV 3/3] END n_estimators=400;, score=(train=1.000, test=0.474) total time=   7.2s\n[CV 1/3] END n_estimators=500;, score=(train=1.000, test=0.463) total time=   9.0s\n[CV 2/3] END n_estimators=500;, score=(train=1.000, test=0.479) total time=   9.5s\n[CV 3/3] END n_estimators=500;, score=(train=1.000, test=0.468) total time=   9.1s\n[CV 1/3] END n_estimators=600;, score=(train=1.000, test=0.467) total time=  10.8s\n[CV 2/3] END n_estimators=600;, score=(train=1.000, test=0.473) total time=  11.2s\n[CV 3/3] END n_estimators=600;, score=(train=1.000, test=0.476) total time=  10.8s\n[CV 1/3] END n_estimators=700;, score=(train=1.000, test=0.468) total time=  13.1s\n[CV 2/3] END n_estimators=700;, score=(train=1.000, test=0.478) total time=  12.6s\n[CV 3/3] END n_estimators=700;, score=(train=1.000, test=0.475) total time=  12.7s\n[CV 1/3] END n_estimators=800;, score=(train=1.000, test=0.469) total time=  14.5s\n[CV 2/3] END n_estimators=800;, score=(train=1.000, test=0.472) total time=  14.5s\n[CV 3/3] END n_estimators=800;, score=(train=1.000, test=0.473) total time=  14.5s\n[CV 1/3] END n_estimators=900;, score=(train=1.000, test=0.467) total time=  16.3s\n[CV 2/3] END n_estimators=900;, score=(train=1.000, test=0.478) total time=  16.1s\n[CV 3/3] END n_estimators=900;, score=(train=1.000, test=0.477) total time=  16.7s\n[CV 1/3] END n_estimators=1000;, score=(train=1.000, test=0.469) total time=  17.9s\n[CV 2/3] END n_estimators=1000;, score=(train=1.000, test=0.474) total time=  18.2s\n[CV 3/3] END n_estimators=1000;, score=(train=1.000, test=0.482) total time=  18.0s\nFitting 3 folds for each of 5 candidates, totalling 15 fits\n[CV 1/3] END ...........C=1;, score=(train=0.367, test=0.358) total time=   0.1s\n[CV 2/3] END ...........C=1;, score=(train=0.359, test=0.373) total time=   0.2s\n[CV 3/3] END ...........C=1;, score=(train=0.368, test=0.353) total time=   0.2s\n[CV 1/3] END ...........C=5;, score=(train=0.368, test=0.360) total time=   0.2s\n[CV 2/3] END ...........C=5;, score=(train=0.362, test=0.374) total time=   0.2s\n[CV 3/3] END ...........C=5;, score=(train=0.370, test=0.355) total time=   0.2s\n[CV 1/3] END ..........C=10;, score=(train=0.368, test=0.359) total time=   0.2s\n[CV 2/3] END ..........C=10;, score=(train=0.362, test=0.374) total time=   0.2s\n[CV 3/3] END ..........C=10;, score=(train=0.369, test=0.356) total time=   0.2s\n[CV 1/3] END ..........C=50;, score=(train=0.368, test=0.360) total time=   0.2s\n[CV 2/3] END ..........C=50;, score=(train=0.362, test=0.374) total time=   0.2s\n[CV 3/3] END ..........C=50;, score=(train=0.369, test=0.355) total time=   0.2s\n[CV 1/3] END .........C=100;, score=(train=0.368, test=0.360) total time=   0.2s\n[CV 2/3] END .........C=100;, score=(train=0.362, test=0.374) total time=   0.2s\n[CV 3/3] END .........C=100;, score=(train=0.369, test=0.355) total time=   0.2s\nFitting 3 folds for each of 56 candidates, totalling 168 fits\n[CV 1/3] END metric=minkowski, n_neighbors=1;, score=(train=1.000, test=0.383) total time=   0.1s\n[CV 2/3] END metric=minkowski, n_neighbors=1;, score=(train=1.000, test=0.377) total time=   0.1s\n[CV 3/3] END metric=minkowski, n_neighbors=1;, score=(train=1.000, test=0.385) total time=   0.1s\n[CV 1/3] END metric=minkowski, n_neighbors=3;, score=(train=0.644, test=0.405) total time=   0.1s\n[CV 2/3] END metric=minkowski, n_neighbors=3;, score=(train=0.647, test=0.411) total time=   0.2s\n[CV 3/3] END metric=minkowski, n_neighbors=3;, score=(train=0.640, test=0.414) total time=   0.1s\n[CV 1/3] END metric=minkowski, n_neighbors=5;, score=(train=0.597, test=0.420) total time=   0.1s\n[CV 2/3] END metric=minkowski, n_neighbors=5;, score=(train=0.594, test=0.427) total time=   0.1s\n[CV 3/3] END metric=minkowski, n_neighbors=5;, score=(train=0.588, test=0.428) total time=   0.1s\n[CV 1/3] END metric=minkowski, n_neighbors=7;, score=(train=0.556, test=0.429) total time=   0.1s\n[CV 2/3] END metric=minkowski, n_neighbors=7;, score=(train=0.561, test=0.437) total time=   0.1s\n[CV 3/3] END metric=minkowski, n_neighbors=7;, score=(train=0.554, test=0.430) total time=   0.1s\n[CV 1/3] END metric=minkowski, n_neighbors=9;, score=(train=0.545, test=0.435) total time=   0.1s\n[CV 2/3] END metric=minkowski, n_neighbors=9;, score=(train=0.538, test=0.437) total time=   0.1s\n[CV 3/3] END metric=minkowski, n_neighbors=9;, score=(train=0.537, test=0.442) total time=   0.1s\n[CV 1/3] END metric=minkowski, n_neighbors=11;, score=(train=0.532, test=0.438) total time=   0.2s\n[CV 2/3] END metric=minkowski, n_neighbors=11;, score=(train=0.521, test=0.448) total time=   0.2s\n[CV 3/3] END metric=minkowski, n_neighbors=11;, score=(train=0.519, test=0.443) total time=   0.2s\n[CV 1/3] END metric=minkowski, n_neighbors=13;, score=(train=0.521, test=0.440) total time=   0.2s\n[CV 2/3] END metric=minkowski, n_neighbors=13;, score=(train=0.512, test=0.444) total time=   0.2s\n[CV 3/3] END metric=minkowski, n_neighbors=13;, score=(train=0.515, test=0.439) total time=   0.2s\n[CV 1/3] END metric=euclidean, n_neighbors=1;, score=(train=1.000, test=0.383) total time=   0.1s\n[CV 2/3] END metric=euclidean, n_neighbors=1;, score=(train=1.000, test=0.377) total time=   0.1s\n[CV 3/3] END metric=euclidean, n_neighbors=1;, score=(train=1.000, test=0.385) total time=   0.1s\n[CV 1/3] END metric=euclidean, n_neighbors=3;, score=(train=0.644, test=0.405) total time=   0.1s\n[CV 2/3] END metric=euclidean, n_neighbors=3;, score=(train=0.647, test=0.411) total time=   0.1s\n[CV 3/3] END metric=euclidean, n_neighbors=3;, score=(train=0.640, test=0.414) total time=   0.1s\n[CV 1/3] END metric=euclidean, n_neighbors=5;, score=(train=0.597, test=0.420) total time=   0.1s\n[CV 2/3] END metric=euclidean, n_neighbors=5;, score=(train=0.594, test=0.427) total time=   0.1s\n[CV 3/3] END metric=euclidean, n_neighbors=5;, score=(train=0.588, test=0.428) total time=   0.1s\n[CV 1/3] END metric=euclidean, n_neighbors=7;, score=(train=0.556, test=0.429) total time=   0.2s\n[CV 2/3] END metric=euclidean, n_neighbors=7;, score=(train=0.561, test=0.437) total time=   0.2s\n[CV 3/3] END metric=euclidean, n_neighbors=7;, score=(train=0.554, test=0.430) total time=   0.1s\n[CV 1/3] END metric=euclidean, n_neighbors=9;, score=(train=0.545, test=0.435) total time=   0.1s\n[CV 2/3] END metric=euclidean, n_neighbors=9;, score=(train=0.538, test=0.437) total time=   0.1s\n[CV 3/3] END metric=euclidean, n_neighbors=9;, score=(train=0.537, test=0.442) total time=   0.1s\n[CV 1/3] END metric=euclidean, n_neighbors=11;, score=(train=0.532, test=0.438) total time=   0.2s\n[CV 2/3] END metric=euclidean, n_neighbors=11;, score=(train=0.521, test=0.448) total time=   0.2s\n[CV 3/3] END metric=euclidean, n_neighbors=11;, score=(train=0.519, test=0.443) total time=   0.2s\n[CV 1/3] END metric=euclidean, n_neighbors=13;, score=(train=0.521, test=0.440) total time=   0.2s\n[CV 2/3] END metric=euclidean, n_neighbors=13;, score=(train=0.512, test=0.444) total time=   0.3s\n[CV 3/3] END metric=euclidean, n_neighbors=13;, score=(train=0.515, test=0.439) total time=   0.3s\n[CV 1/3] END metric=manhattan, n_neighbors=1;, score=(train=1.000, test=0.377) total time=   0.2s\n[CV 2/3] END metric=manhattan, n_neighbors=1;, score=(train=1.000, test=0.388) total time=   0.2s\n[CV 3/3] END metric=manhattan, n_neighbors=1;, score=(train=1.000, test=0.391) total time=   0.2s\n[CV 1/3] END metric=manhattan, n_neighbors=3;, score=(train=0.642, test=0.403) total time=   0.2s\n[CV 2/3] END metric=manhattan, n_neighbors=3;, score=(train=0.641, test=0.415) total time=   0.2s\n[CV 3/3] END metric=manhattan, n_neighbors=3;, score=(train=0.640, test=0.405) total time=   0.2s\n[CV 1/3] END metric=manhattan, n_neighbors=5;, score=(train=0.591, test=0.427) total time=   0.2s\n[CV 2/3] END metric=manhattan, n_neighbors=5;, score=(train=0.589, test=0.427) total time=   0.2s\n[CV 3/3] END metric=manhattan, n_neighbors=5;, score=(train=0.585, test=0.424) total time=   0.2s\n[CV 1/3] END metric=manhattan, n_neighbors=7;, score=(train=0.557, test=0.434) total time=   0.2s\n[CV 2/3] END metric=manhattan, n_neighbors=7;, score=(train=0.552, test=0.434) total time=   0.2s\n[CV 3/3] END metric=manhattan, n_neighbors=7;, score=(train=0.557, test=0.440) total time=   0.3s\n[CV 1/3] END metric=manhattan, n_neighbors=9;, score=(train=0.538, test=0.438) total time=   0.2s\n[CV 2/3] END metric=manhattan, n_neighbors=9;, score=(train=0.534, test=0.438) total time=   0.3s\n[CV 3/3] END metric=manhattan, n_neighbors=9;, score=(train=0.538, test=0.442) total time=   0.2s\n[CV 1/3] END metric=manhattan, n_neighbors=11;, score=(train=0.531, test=0.447) total time=   0.2s\n[CV 2/3] END metric=manhattan, n_neighbors=11;, score=(train=0.517, test=0.434) total time=   0.3s\n[CV 3/3] END metric=manhattan, n_neighbors=11;, score=(train=0.527, test=0.446) total time=   0.3s\n[CV 1/3] END metric=manhattan, n_neighbors=13;, score=(train=0.516, test=0.440) total time=   0.3s\n[CV 2/3] END metric=manhattan, n_neighbors=13;, score=(train=0.513, test=0.443) total time=   0.3s\n[CV 3/3] END metric=manhattan, n_neighbors=13;, score=(train=0.510, test=0.443) total time=   0.3s\n[CV 1/3] END metric=chebyshev, n_neighbors=1;, score=(train=1.000, test=0.375) total time=   0.1s\n[CV 2/3] END metric=chebyshev, n_neighbors=1;, score=(train=1.000, test=0.376) total time=   0.1s\n[CV 3/3] END metric=chebyshev, n_neighbors=1;, score=(train=1.000, test=0.374) total time=   0.1s\n[CV 1/3] END metric=chebyshev, n_neighbors=3;, score=(train=0.639, test=0.399) total time=   0.1s\n[CV 2/3] END metric=chebyshev, n_neighbors=3;, score=(train=0.636, test=0.407) total time=   0.1s\n[CV 3/3] END metric=chebyshev, n_neighbors=3;, score=(train=0.630, test=0.405) total time=   0.1s\n[CV 1/3] END metric=chebyshev, n_neighbors=5;, score=(train=0.593, test=0.409) total time=   0.1s\n[CV 2/3] END metric=chebyshev, n_neighbors=5;, score=(train=0.583, test=0.419) total time=   0.1s\n[CV 3/3] END metric=chebyshev, n_neighbors=5;, score=(train=0.577, test=0.425) total time=   0.1s\n[CV 1/3] END metric=chebyshev, n_neighbors=7;, score=(train=0.554, test=0.417) total time=   0.1s\n[CV 2/3] END metric=chebyshev, n_neighbors=7;, score=(train=0.557, test=0.428) total time=   0.1s\n[CV 3/3] END metric=chebyshev, n_neighbors=7;, score=(train=0.548, test=0.431) total time=   0.1s\n[CV 1/3] END metric=chebyshev, n_neighbors=9;, score=(train=0.531, test=0.419) total time=   0.1s\n[CV 2/3] END metric=chebyshev, n_neighbors=9;, score=(train=0.532, test=0.435) total time=   0.2s\n[CV 3/3] END metric=chebyshev, n_neighbors=9;, score=(train=0.528, test=0.428) total time=   0.1s\n[CV 1/3] END metric=chebyshev, n_neighbors=11;, score=(train=0.519, test=0.427) total time=   0.1s\n[CV 2/3] END metric=chebyshev, n_neighbors=11;, score=(train=0.515, test=0.428) total time=   0.1s\n[CV 3/3] END metric=chebyshev, n_neighbors=11;, score=(train=0.514, test=0.429) total time=   0.1s\n[CV 1/3] END metric=chebyshev, n_neighbors=13;, score=(train=0.509, test=0.424) total time=   0.1s\n[CV 2/3] END metric=chebyshev, n_neighbors=13;, score=(train=0.506, test=0.434) total time=   0.1s\n[CV 3/3] END metric=chebyshev, n_neighbors=13;, score=(train=0.508, test=0.431) total time=   0.1s\n[CV 1/3] END metric=cosine, n_neighbors=1;, score=(train=1.000, test=0.382) total time=   0.2s\n[CV 2/3] END metric=cosine, n_neighbors=1;, score=(train=1.000, test=0.373) total time=   0.3s\n[CV 3/3] END metric=cosine, n_neighbors=1;, score=(train=1.000, test=0.383) total time=   0.2s\n[CV 1/3] END metric=cosine, n_neighbors=3;, score=(train=0.639, test=0.404) total time=   0.3s\n[CV 2/3] END metric=cosine, n_neighbors=3;, score=(train=0.633, test=0.404) total time=   0.3s\n[CV 3/3] END metric=cosine, n_neighbors=3;, score=(train=0.634, test=0.407) total time=   0.3s\n[CV 1/3] END metric=cosine, n_neighbors=5;, score=(train=0.590, test=0.423) total time=   0.3s\n[CV 2/3] END metric=cosine, n_neighbors=5;, score=(train=0.585, test=0.434) total time=   0.4s\n[CV 3/3] END metric=cosine, n_neighbors=5;, score=(train=0.582, test=0.423) total time=   0.3s\n[CV 1/3] END metric=cosine, n_neighbors=7;, score=(train=0.555, test=0.422) total time=   0.3s\n[CV 2/3] END metric=cosine, n_neighbors=7;, score=(train=0.549, test=0.431) total time=   0.4s\n[CV 3/3] END metric=cosine, n_neighbors=7;, score=(train=0.548, test=0.430) total time=   0.3s\n[CV 1/3] END metric=cosine, n_neighbors=9;, score=(train=0.539, test=0.427) total time=   0.5s\n[CV 2/3] END metric=cosine, n_neighbors=9;, score=(train=0.529, test=0.435) total time=   0.4s\n[CV 3/3] END metric=cosine, n_neighbors=9;, score=(train=0.528, test=0.438) total time=   0.3s\n[CV 1/3] END metric=cosine, n_neighbors=11;, score=(train=0.523, test=0.427) total time=   0.4s\n[CV 2/3] END metric=cosine, n_neighbors=11;, score=(train=0.512, test=0.439) total time=   0.4s\n[CV 3/3] END metric=cosine, n_neighbors=11;, score=(train=0.513, test=0.435) total time=   0.3s\n[CV 1/3] END metric=cosine, n_neighbors=13;, score=(train=0.510, test=0.431) total time=   0.3s\n[CV 2/3] END metric=cosine, n_neighbors=13;, score=(train=0.507, test=0.438) total time=   0.4s\n[CV 3/3] END metric=cosine, n_neighbors=13;, score=(train=0.498, test=0.441) total time=   0.3s\n[CV 1/3] END metric=hamming, n_neighbors=1;, score=(train=1.000, test=0.244) total time=   0.3s\n[CV 2/3] END metric=hamming, n_neighbors=1;, score=(train=1.000, test=0.057) total time=   0.3s\n[CV 3/3] END metric=hamming, n_neighbors=1;, score=(train=1.000, test=0.168) total time=   0.4s\n[CV 1/3] END metric=hamming, n_neighbors=3;, score=(train=0.245, test=0.245) total time=   0.3s\n[CV 2/3] END metric=hamming, n_neighbors=3;, score=(train=0.301, test=0.245) total time=   0.3s\n[CV 3/3] END metric=hamming, n_neighbors=3;, score=(train=0.414, test=0.168) total time=   0.3s\n[CV 1/3] END metric=hamming, n_neighbors=5;, score=(train=0.245, test=0.245) total time=   0.3s\n[CV 2/3] END metric=hamming, n_neighbors=5;, score=(train=0.245, test=0.245) total time=   0.3s\n[CV 3/3] END metric=hamming, n_neighbors=5;, score=(train=0.413, test=0.245) total time=   0.3s\n[CV 1/3] END metric=hamming, n_neighbors=7;, score=(train=0.245, test=0.245) total time=   0.3s\n[CV 2/3] END metric=hamming, n_neighbors=7;, score=(train=0.245, test=0.245) total time=   0.3s\n[CV 3/3] END metric=hamming, n_neighbors=7;, score=(train=0.245, test=0.245) total time=   0.3s\n[CV 1/3] END metric=hamming, n_neighbors=9;, score=(train=0.245, test=0.245) total time=   0.3s\n[CV 2/3] END metric=hamming, n_neighbors=9;, score=(train=0.245, test=0.245) total time=   0.3s\n[CV 3/3] END metric=hamming, n_neighbors=9;, score=(train=0.245, test=0.245) total time=   0.3s\n[CV 1/3] END metric=hamming, n_neighbors=11;, score=(train=0.245, test=0.245) total time=   0.3s\n[CV 2/3] END metric=hamming, n_neighbors=11;, score=(train=0.245, test=0.245) total time=   0.3s\n[CV 3/3] END metric=hamming, n_neighbors=11;, score=(train=0.245, test=0.245) total time=   0.3s\n[CV 1/3] END metric=hamming, n_neighbors=13;, score=(train=0.245, test=0.245) total time=   0.3s\n[CV 2/3] END metric=hamming, n_neighbors=13;, score=(train=0.245, test=0.245) total time=   0.3s\n[CV 3/3] END metric=hamming, n_neighbors=13;, score=(train=0.245, test=0.245) total time=   0.3s\n[CV 1/3] END metric=canberra, n_neighbors=1;, score=(train=1.000, test=0.365) total time=   0.4s\n[CV 2/3] END metric=canberra, n_neighbors=1;, score=(train=1.000, test=0.366) total time=   0.4s\n[CV 3/3] END metric=canberra, n_neighbors=1;, score=(train=1.000, test=0.353) total time=   0.6s\n[CV 1/3] END metric=canberra, n_neighbors=3;, score=(train=0.614, test=0.381) total time=   0.7s\n[CV 2/3] END metric=canberra, n_neighbors=3;, score=(train=0.607, test=0.382) total time=   0.4s\n[CV 3/3] END metric=canberra, n_neighbors=3;, score=(train=0.626, test=0.374) total time=   0.4s\n[CV 1/3] END metric=canberra, n_neighbors=5;, score=(train=0.565, test=0.403) total time=   0.4s\n[CV 2/3] END metric=canberra, n_neighbors=5;, score=(train=0.562, test=0.398) total time=   0.4s\n[CV 3/3] END metric=canberra, n_neighbors=5;, score=(train=0.564, test=0.398) total time=   0.4s\n[CV 1/3] END metric=canberra, n_neighbors=7;, score=(train=0.533, test=0.405) total time=   0.4s\n[CV 2/3] END metric=canberra, n_neighbors=7;, score=(train=0.533, test=0.399) total time=   0.4s\n[CV 3/3] END metric=canberra, n_neighbors=7;, score=(train=0.528, test=0.405) total time=   0.5s\n[CV 1/3] END metric=canberra, n_neighbors=9;, score=(train=0.523, test=0.412) total time=   0.4s\n[CV 2/3] END metric=canberra, n_neighbors=9;, score=(train=0.510, test=0.406) total time=   0.4s\n[CV 3/3] END metric=canberra, n_neighbors=9;, score=(train=0.510, test=0.419) total time=   0.4s\n[CV 1/3] END metric=canberra, n_neighbors=11;, score=(train=0.502, test=0.406) total time=   0.4s\n[CV 2/3] END metric=canberra, n_neighbors=11;, score=(train=0.497, test=0.412) total time=   0.4s\n[CV 3/3] END metric=canberra, n_neighbors=11;, score=(train=0.503, test=0.418) total time=   0.4s\n[CV 1/3] END metric=canberra, n_neighbors=13;, score=(train=0.491, test=0.409) total time=   0.4s\n[CV 2/3] END metric=canberra, n_neighbors=13;, score=(train=0.488, test=0.417) total time=   0.4s\n[CV 3/3] END metric=canberra, n_neighbors=13;, score=(train=0.486, test=0.419) total time=   0.4s\n[CV 1/3] END metric=braycurtis, n_neighbors=1;, score=(train=1.000, test=0.375) total time=   0.2s\n[CV 2/3] END metric=braycurtis, n_neighbors=1;, score=(train=1.000, test=0.385) total time=   0.2s\n[CV 3/3] END metric=braycurtis, n_neighbors=1;, score=(train=1.000, test=0.385) total time=   0.2s\n[CV 1/3] END metric=braycurtis, n_neighbors=3;, score=(train=0.639, test=0.402) total time=   0.2s\n[CV 2/3] END metric=braycurtis, n_neighbors=3;, score=(train=0.638, test=0.412) total time=   0.2s\n[CV 3/3] END metric=braycurtis, n_neighbors=3;, score=(train=0.638, test=0.409) total time=   0.3s\n[CV 1/3] END metric=braycurtis, n_neighbors=5;, score=(train=0.592, test=0.425) total time=   0.3s\n[CV 2/3] END metric=braycurtis, n_neighbors=5;, score=(train=0.582, test=0.428) total time=   0.3s\n[CV 3/3] END metric=braycurtis, n_neighbors=5;, score=(train=0.582, test=0.436) total time=   0.3s\n[CV 1/3] END metric=braycurtis, n_neighbors=7;, score=(train=0.559, test=0.438) total time=   0.3s\n[CV 2/3] END metric=braycurtis, n_neighbors=7;, score=(train=0.549, test=0.434) total time=   0.3s\n[CV 3/3] END metric=braycurtis, n_neighbors=7;, score=(train=0.554, test=0.442) total time=   0.3s\n[CV 1/3] END metric=braycurtis, n_neighbors=9;, score=(train=0.537, test=0.438) total time=   0.6s\n[CV 2/3] END metric=braycurtis, n_neighbors=9;, score=(train=0.529, test=0.440) total time=   0.3s\n[CV 3/3] END metric=braycurtis, n_neighbors=9;, score=(train=0.528, test=0.445) total time=   0.3s\n[CV 1/3] END metric=braycurtis, n_neighbors=11;, score=(train=0.522, test=0.440) total time=   0.3s\n[CV 2/3] END metric=braycurtis, n_neighbors=11;, score=(train=0.521, test=0.439) total time=   0.3s\n[CV 3/3] END metric=braycurtis, n_neighbors=11;, score=(train=0.525, test=0.448) total time=   0.3s\n[CV 1/3] END metric=braycurtis, n_neighbors=13;, score=(train=0.515, test=0.435) total time=   0.3s\n[CV 2/3] END metric=braycurtis, n_neighbors=13;, score=(train=0.512, test=0.434) total time=   0.3s\n[CV 3/3] END metric=braycurtis, n_neighbors=13;, score=(train=0.509, test=0.449) total time=   0.3s\n","output_type":"stream"}]},{"cell_type":"code","source":"df_score = pd.DataFrame(scores,columns=['model','best_score','best_params'])\nprint(df_score)","metadata":{"execution":{"iopub.status.busy":"2023-01-21T13:14:51.948522Z","iopub.execute_input":"2023-01-21T13:14:51.949190Z","iopub.status.idle":"2023-01-21T13:14:51.965063Z","shell.execute_reply.started":"2023-01-21T13:14:51.949153Z","shell.execute_reply":"2023-01-21T13:14:51.963924Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"                 model  best_score                                 best_params\n0                  svm    0.422222                  {'C': 30, 'kernel': 'rbf'}\n1        random_forest    0.475579                       {'n_estimators': 400}\n2  logistic_regression    0.363194                                  {'C': 100}\n3                  KNN    0.443171  {'metric': 'minkowski', 'n_neighbors': 11}\n","output_type":"stream"}]},{"cell_type":"code","source":"# SVM\nC = 30\nkernel = \"rbf\"\n\nsvm_clf = svm.SVC(kernel=kernel, C=C, gamma='auto')\nsvm_clf.fit(X_train, y_train)\n\nsvm_clf_score_train = svm_clf.score(X_train, y_train)\nsvm_clf_score_test = svm_clf.score(X_test, y_test)\n\nprint(f\"Train accuracy - SVM: {svm_clf_score_train}\")\nprint(f\"Test accuracy - SVM: {svm_clf_score_test}\")","metadata":{"execution":{"iopub.status.busy":"2023-01-21T13:16:41.844000Z","iopub.execute_input":"2023-01-21T13:16:41.844382Z","iopub.status.idle":"2023-01-21T13:16:56.708449Z","shell.execute_reply.started":"2023-01-21T13:16:41.844349Z","shell.execute_reply":"2023-01-21T13:16:56.707424Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Train accuracy - SVM: 0.44016203703703705\nTest accuracy - SVM: 0.4305555555555556\n","output_type":"stream"}]},{"cell_type":"code","source":"# Random Forest\nn_estimators = 400\n\nrf_clf = RandomForestClassifier(n_estimators=n_estimators)\nrf_clf.fit(X_train, y_train)\n\nrf_clf_score_train = rf_clf.score(X_train, y_train)\nrf_clf_score_test = rf_clf.score(X_test, y_test)\n\nprint(f\"Train accuracy - Random Forest: {rf_clf_score_train}\")\nprint(f\"Test accuracy - Random Forest: {rf_clf_score_test}\")","metadata":{"execution":{"iopub.status.busy":"2023-01-21T13:16:56.710466Z","iopub.execute_input":"2023-01-21T13:16:56.711154Z","iopub.status.idle":"2023-01-21T13:17:14.429159Z","shell.execute_reply.started":"2023-01-21T13:16:56.711117Z","shell.execute_reply":"2023-01-21T13:17:14.428158Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Train accuracy - Random Forest: 1.0\nTest accuracy - Random Forest: 0.5976851851851852\n","output_type":"stream"}]},{"cell_type":"code","source":"# Logistic Regression\nC = 100\n\nlr_clf = LogisticRegression(solver='liblinear', multi_class='auto', C=C)\nlr_clf.fit(X_train, y_train)\n\nlr_clf_score_train = lr_clf.score(X_train, y_train)\nlr_clf_score_test = lr_clf.score(X_test, y_test)\n\nprint(f\"Train accuracy - Logistic Regression: {lr_clf_score_train}\")\nprint(f\"Test accuracy - Logistic Regression: {lr_clf_score_test}\")","metadata":{"execution":{"iopub.status.busy":"2023-01-21T13:17:14.430793Z","iopub.execute_input":"2023-01-21T13:17:14.431170Z","iopub.status.idle":"2023-01-21T13:17:17.122464Z","shell.execute_reply.started":"2023-01-21T13:17:14.431134Z","shell.execute_reply":"2023-01-21T13:17:17.119042Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Train accuracy - Logistic Regression: 0.440625\nTest accuracy - Logistic Regression: 0.4324074074074074\n","output_type":"stream"}]},{"cell_type":"code","source":"# k-NN\nmetric = \"minkowski\"\nn_neighbors = 11\n\nknn_clf = KNeighborsClassifier(metric=metric, n_neighbors=n_neighbors)\nknn_clf.fit(X_train, y_train)\n\nknn_clf_score_train = knn_clf.score(X_train, y_train)\nknn_clf_score_test = knn_clf.score(X_test, y_test)\n\nprint(f\"Train accuracy - k-NN: {knn_clf_score_train}\")\nprint(f\"Test accuracy - k-NN: {knn_clf_score_test}\")","metadata":{"execution":{"iopub.status.busy":"2023-01-21T13:17:17.124714Z","iopub.execute_input":"2023-01-21T13:17:17.125362Z","iopub.status.idle":"2023-01-21T13:17:19.390666Z","shell.execute_reply.started":"2023-01-21T13:17:17.125322Z","shell.execute_reply":"2023-01-21T13:17:19.389487Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Train accuracy - k-NN: 0.5508101851851852\nTest accuracy - k-NN: 0.47824074074074074\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}